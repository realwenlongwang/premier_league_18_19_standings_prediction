{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "rcParams['figure.dpi'] = 350\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['font.family'] = 'StixGeneral'\n",
    "rcParams['font.size'] = 20\n",
    "rcParams['figure.figsize'] = (10,10)\n",
    "rcParams['axes.labelsize'] = 'large'\n",
    "rcParams['xtick.labelsize'] = 20\n",
    "rcParams['ytick.labelsize'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the webpage\n",
    "---\n",
    "In order to increase the readability of this notebook, the web scrapping process is written in the `web_scrapper` class and imported to this notebook. It scraps the summary and standings tables from https://www.transfermarkt.com/premier-league/startseite/wettbewerb/GB1/plus/?saison_id=2017 in the range between 2005 to 2017 and convert merge it to a giant dictionary with the year as the key and the summary detail of premier league in that year as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_scrapper import web_scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_web_scrapper = web_scrapper()\n",
    "try:\n",
    "    my_web_scrapper.connect()\n",
    "except requests.ConnectionError as detail:\n",
    "    print(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dfs = my_web_scrapper.digest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_dfs[2005].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "---\n",
    "As we see above in the table, the data scrapped from https://www.transfermarkt.com are in good shape. However, we have to clean this data for machine learning's sake since model will only accept numeric inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_summary_df = pd.DataFrame()\n",
    "for key, df in summary_dfs.items():\n",
    "    df[\"Year\"] = key\n",
    "    big_summary_df = pd.concat((big_summary_df, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_summary_df.reset_index(drop=True, inplace=True)\n",
    "big_summary_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of readability, we can use a helper class which helps us to move the unit of both \"Avg. Market Values\" and \"Total Market Values\" to the column names. Then it can change all the cells that are numeric values to a proper data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_cleaner import df_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df_cleaner = df_cleaner()\n",
    "numeric_big_summary_df = my_df_cleaner.cook(big_summary_df)\n",
    "numeric_big_summary_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_big_summary_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_big_summary_df[numeric_big_summary_df[\"Year\"]!=2018].pivot_table(index=\"Year\", columns=\"Club Short Name\", values=\"Position\").dropna(axis=1).plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "---\n",
    "Before we feed the data to the model, it is important that we can analyse the data both visually and numerically first. It will give us more intuition of the problem we are trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_strong_corr_red(val):\n",
    "    \"\"\"\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: red'` for strong correlations\n",
    "    , black otherwise.\n",
    "    \"\"\"\n",
    "    color = 'red' if (val > 0.6 or val < -0.6)  else 'black'\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the correlation table will be most intuitive, we can take a look which two numeric features have a strong correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numeric_big_summary_df.corr().style.applymap(color_strong_corr_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that total market values of a club has a relationship with both position and goal difference. Let's visualise this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(numeric_big_summary_df[numeric_big_summary_df[\"Year\"]!=2018].iloc[:, :-1], height=5)\n",
    "g = g.map_upper(plt.scatter)\n",
    "g = g.map_lower(sns.kdeplot)\n",
    "g = g.map_diag(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_axis = 0\n",
    "y_axis = -3\n",
    "\n",
    "numeric_big_summary_df[numeric_big_summary_df[\"Year\"]!=2018].iloc[:, [x_axis, y_axis]].plot(kind=\"scatter\", x=numeric_big_summary_df.columns[x_axis], y=numeric_big_summary_df.columns[y_axis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "---\n",
    "Before regression, we need a mechanism to help us evaluating our prediction result. Thus, we need to split the dataset into training set and testing set.\n",
    "\n",
    "Firstly, we need to split the 2018 year dataset since this is our objective in this project, to predict the standing of this year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_df = numeric_big_summary_df.copy()\n",
    "prediction_input_df = numeric_big_summary_df[numeric_big_summary_df[\"Year\"] == 2018]\n",
    "training_set_df.drop(prediction_input_df.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the training set and test set will use abbreviated column names. However, for readability, plotting will still use the full name DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_col_name_list = training_set_df.columns\n",
    "training_set_df.rename(columns={\n",
    "    old_col_name_list[0]: \"avg_mv\",\n",
    "    old_col_name_list[1]: \"avg_age\",\n",
    "    old_col_name_list[2]: \"full\",\n",
    "    old_col_name_list[3]: \"short\",\n",
    "    old_col_name_list[4]: \"total_mv\",\n",
    "    old_col_name_list[5]: \"pos\",\n",
    "    old_col_name_list[6]: \"gd\",\n",
    "    old_col_name_list[7]: \"pts\",\n",
    "    old_col_name_list[8]: \"year\",\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, the dataset need to be split to training set and testing set. The radio of training set is 80% and of testing set is 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set_df = training_set_df.sample(frac=0.2)\n",
    "training_set_df.drop(testing_set_df.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look what two sets look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_df.plot(kind=\"scatter\", x=training_set_df.columns[x_axis], y=training_set_df.columns[y_axis])\n",
    "plt.xlabel(numeric_big_summary_df.columns[x_axis])\n",
    "plt.ylabel(numeric_big_summary_df.columns[y_axis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "---\n",
    "Firstly, let's use a linear hypothesis function to describe the relationship, and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linregress_CIs(xd,yd,conf=0.95):\n",
    "    \"\"\"Linear regression CIs FTW!\"\"\"\n",
    "    alpha=1.-conf   # significance\n",
    "    n = xd.size   # data sample size\n",
    "    x = np.linspace(xd.min(),xd.max(),1000)\n",
    "        \n",
    "    # Predicted values from fitted model:\n",
    "    a, b, r, p, err = scipy.stats.linregress(xd,yd)\n",
    "    y = a*x+b\n",
    "    \n",
    "    sd = 1./(n-2.)*np.sum((yd-a*xd-b)**2)\n",
    "    sd = np.sqrt(sd)\n",
    "    sxd = np.sum((xd-xd.mean())**2) #SS total\n",
    "    sx  = (x-xd.mean())**2 # variance of each x\n",
    "    \n",
    "    # quantile of student's t distribution for p=1-alpha/2\n",
    "    q = scipy.stats.t.ppf(1.-alpha/2, n-2)\n",
    "    # get the upper and lower CI:\n",
    "    dy = q*sd*np.sqrt( 1./n + sx/sxd )\n",
    "    yl = y-dy\n",
    "    yu = y+dy\n",
    "    \n",
    "    return yl,yu,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_mod = smf.ols(formula=\"pts ~ avg_mv\", data=training_set_df).fit()\n",
    "yl,yu,xd = linregress_CIs(training_set_df.avg_mv.values, training_set_df.pts.values, .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the hypothesis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(training_set_df.avg_mv, training_set_df.pts, label=\"Points\", s=20, alpha=0.6)\n",
    "plt.xlabel(numeric_big_summary_df.columns[x_axis])\n",
    "plt.ylabel(numeric_big_summary_df.columns[y_axis])\n",
    "\n",
    "x = pd.DataFrame({\"avg_mv\": np.linspace(training_set_df.avg_mv.min(),\n",
    "                                       training_set_df.avg_mv.max(),\n",
    "                                       len(training_set_df.avg_mv))})\n",
    "\n",
    "plt.plot(x.avg_mv, linear_mod.predict(x), \"b-\", label='Linear $R^2$=%.2f' % linear_mod.rsquared, alpha=0.9)\n",
    "plt.fill_between(xd, yl, yu, alpha=0.3, facecolor='blue',edgecolor='none')\n",
    "plt.legend(loc='upper left', framealpha=0.5, prop={'size':'small'})\n",
    "plt.title(\"Predicting Club Points Base on Average Market Values\", fontsize=20)\n",
    "\n",
    "linear_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be more intuitive for use to evaluate how good is our model to use a one-number evaluation.\n",
    "To achieve this objective, we can calculate the square mean difference for the test set and prediction, the smaller the loss is, the better the model can predict.\n",
    "\n",
    "$$\n",
    "loss = \\sum_{i=1}^{n} (y_i - h(x_i))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.mean(np.square(testing_set_df.pts - linear_mod.predict(testing_set_df.avg_mv)))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
